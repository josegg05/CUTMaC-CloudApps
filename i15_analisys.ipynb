{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analisis de Datos de la I15 "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data of the I15 NB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"precision\", 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Imports\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Carga de la data.\n",
    "La base de datos SQL posee datos del 01-01-2018 al 31-12-2019 de todos los sensores (a excepción de algunos parecen no estar funcionando) que aparecen en la plataforma Bugatti FAST. De esta base de datos se exportó un dataset con los datos de los sensores pertenecientes a la I15_NB (I15 dirección norte). El dataset \"lean\" es el mismo dataset exportado eliminando las columnas de datos que no utilizo (Vease los drops que se encuentran comentados). Existen dos valores denominados \"Invalid\" -> [0, 1, 2, 3] y \"Failure\" -> [0 - 448] que aún no sé como utilizar porque no sé qué significan sus valores."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data loading\n",
    "The SQL database has data from 01-01-2018 to 31-12-2019 of all the sensors that appear in the Bugatti FAST dashboard (except for some that seem not to be working). From this database a dataset was exported with data from sensors belonging to the I15_NB (I15 northbound). The \"lean\" dataset is the same dataset exported, but eliminating the columns of data that I do not use (see commented \"drops\"). There are two values named \"Invalid\" -> [0, 1, 2, 3] and \"Failure\" -> [0 - 448] that I still don't know how to use because I don't know what their values mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_file_name = \"datasets/la_vegas/i15_bugatti/bugatti_nb_data_lean.csv\"\n",
    "# data_file_name = \"datasets/la_vegas/i15_bugatti/bugatti_nb_data.csv\"\n",
    "\n",
    "data = pd.read_csv(data_file_name)\n",
    "# data = data.drop(columns=['Path', 'RoadIndex', 'RoadwayID', 'SegmentID', 'DeviceID',\n",
    "#                           'Volume1', 'Volume2', 'Volume3', 'Volume4', 'Volume5', 'Volume6',\n",
    "#                           'RoadType', 'Location', 'Polling_Period', 'DayOfWeek',\n",
    "#                           'DateValue', 'HourIdx', 'Holiday'])\n",
    "# data.to_csv('datasets/la_vegas/i15_bugatti/bugatti_nb_data_lean.csv', index=False)\n",
    "\n",
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%   Data Load\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(data['Path'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Invalid Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invalid = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_bad = data[data['Invalid'] == 1]\n",
    "print(data_bad['Invalid'].count())\n",
    "data_bad.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invalid = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_bad = data[data['Invalid'] == 2]\n",
    "print(data_bad['Invalid'].count())\n",
    "data_bad.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invalid = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_bad = data[data['Invalid'] == 3]\n",
    "print(data_bad['Invalid'].count())\n",
    "data_bad.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Valid Values: {len(data['Invalid'][data['Invalid'] == 0])} ({(len(data['Invalid'][data['Invalid'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid Values: {len(data['Invalid'][data['Invalid'] != 0])} ({(len(data['Invalid'][data['Invalid'] != 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 1: {len(data['Invalid'][data['Invalid'] == 1])} ({(len(data['Invalid'][data['Invalid'] == 1])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 2: {len(data['Invalid'][data['Invalid'] == 2])} ({(len(data['Invalid'][data['Invalid'] == 2])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 3: {len(data['Invalid'][data['Invalid'] == 3])} ({(len(data['Invalid'][data['Invalid'] == 3])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Invalid Values: {len(data['Invalid'].unique())}\")\n",
    "hist = data['Invalid'].hist(bins=len(data['Invalid'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zoom on the Invalid values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['Invalid'][data['Invalid'] != 0].hist(bins=len(data['Invalid'].unique()) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data['Invalid'][(data['Invalid'] == 2) & (data['Volume'] == 0) & (data['Occupancy'] == 0)] = 4\n",
    "data_invalid2_special = data.loc[(data['Invalid'] == 2) & (data['Volume'] == 0) & (data['Occupancy'] == 0), 'Invalid']\n",
    "data.loc[(data['Invalid'] == 2) & (data['Volume'] == 0) & (data['Occupancy'] == 0), 'Invalid'] = 0\n",
    "print(f\"Number of Invalid = 2 (Special case): {len(data_invalid2_special)} ({(len(data_invalid2_special)/len(data))*100}%)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['Invalid'][data['Invalid'] != 0].hist(bins=len(data['Invalid'].unique()) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Correct Values: {len(data['Failure'][data['Failure'] == 0])} ({(len(data['Failure'][data['Failure'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Failure Values: {len(data['Failure'][data['Failure'] != 0])} ({(len(data['Failure'][data['Failure'] != 0])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Failure Values: {len(data['Failure'].unique())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se realiza un mapeo de los ID de los detectores a una serie de números del \"0\" a \"N - 1\" (N= cantidad de detectores = 57). Dicha serie está ordenada según la ubicación de los detectores en la autopista, siendo \"0\" el detector que se encuentra más al Sur y \"N-1\" el que se encuentra más al Norte."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The detector IDs are mapped to a series of numbers from \"0\" to \"N - 1\" (N= number of detectors = 57). This series is ordered according to the location of the detectors on the highway, with \"0\" being the southernmost detector and \"N-1\" being the northernmost."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detectors_nb_list = ['440.1.335',  '439.1.334',\n",
    "  '439.2.333',\n",
    "  '439.3.332',\n",
    "  '438.1.331',\n",
    "  '438.2.330',\n",
    "  '438.3.329',\n",
    "  '359.1.325',\n",
    "  '358.1.325',\n",
    "  '358.2.320',\n",
    "  '358.3.319',\n",
    "  '357.1.312',\n",
    "  '357.2.311',\n",
    "  '357.3.310',\n",
    "  '356.1.309',\n",
    "  '356.2.308',\n",
    "  '355.1.156',\n",
    "  '355.2.153',\n",
    "  '355.3.155',\n",
    "  '354.1.79',\n",
    "  '354.2.144',\n",
    "  '354.3.145',\n",
    "  '32.1.142',\n",
    "  '34.1.94',\n",
    "  '39.2.88',\n",
    "  '48.2.83',\n",
    "  '49.1.82',\n",
    "  '49.2.12',\n",
    "  '49.3.15',\n",
    "  '58.2.17',\n",
    "  '59.1.18',\n",
    "  '59.2.18',\n",
    "  '70.2.21',\n",
    "  '71.2.23',\n",
    "  '72.1.22',\n",
    "  '72.2.28',\n",
    "  '89.1.28',\n",
    "  '89.2.30',\n",
    "  '97.1.33',\n",
    "  '97.2.33',\n",
    "  '97.3.38',\n",
    "  '99.1.35',\n",
    "  '110.1.41',\n",
    "  '112.2.44',\n",
    "  '113.2.45',\n",
    "  '122.2.48',\n",
    "  '124.2.49',\n",
    "  '137.1.80',\n",
    "  '138.1.53',\n",
    "  '138.2.55',\n",
    "  '146.2.238',\n",
    "  '148.2.58',\n",
    "  '149.2.240',\n",
    "  '160.2.242',\n",
    "  '396.1.243',\n",
    "  '396.2.246',\n",
    "  '396.3.246',\n",
    "  '397.1.247',\n",
    "  '397.2.248',\n",
    "  '398.1.249',\n",
    "  '398.2.251']\n",
    "print(len(detectors_nb_list))\n",
    "detector_id_map = {}\n",
    "data_unique_detect_ID = data['DetectorID'].unique()\n",
    "\n",
    "count_loss = 0\n",
    "for i in range(len(detectors_nb_list)):\n",
    "    if detectors_nb_list[i] in data_unique_detect_ID:\n",
    "        detector_id_map[detectors_nb_list[i]] = i - count_loss\n",
    "    else:\n",
    "        count_loss += 1\n",
    "print(f'Detectors lost = {count_loss}')\n",
    "\n",
    "data_detect_ID = data['DetectorID']\n",
    "\n",
    "data_detect_new_ID = pd.Series([detector_id_map[i] for i in data_detect_ID])\n",
    "print(data_detect_new_ID)\n",
    "data['DetectID'] = data_detect_new_ID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se trasforma la columna 'DateTimeStamp' de string a un formato pd.datetime64 para poder ordenar los datos de forma cronológica y para poder analizar los períodos de muestreo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The column 'DateTimeStamp' is transformed from string to a pd.datetime64 format to be able to sort the data chronologically and to be able to analyze the sampling periods."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['DateTimeStamp'] = pd.to_datetime(data['DateTimeStamp'])\n",
    "data = data.sort_values(by=['DateTimeStamp','DetectID'],ascending=[True, True])\n",
    "\n",
    "date_time_obj = data['DateTimeStamp'].iloc[0]\n",
    "print('Date:', date_time_obj.date())\n",
    "print('Time:', date_time_obj.time())\n",
    "print('Minute:', date_time_obj.time().minute)\n",
    "print('Date-time:', date_time_obj)\n",
    "\n",
    "print(data['DateTimeStamp'].unique())\n",
    "print(len(data['DateTimeStamp'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Convertir columna 'DateTimeStamp' a pd.dateTime64 object y sortearlo ascendentemente\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se realiza un análisis de los tiempos de muestreo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An analysis of sampling times is performed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_unq = pd.Series(data['DateTimeStamp'].unique())\n",
    "date_rest = []\n",
    "date_rare = []\n",
    "date_no_15 = []\n",
    "for i in range(len(date_unq)-1):\n",
    "    if date_unq[i+1].time().hour == date_unq[i].time().hour:\n",
    "        rest = date_unq[i+1].time().minute - date_unq[i].time().minute\n",
    "    elif (date_unq[i+1].time().hour > date_unq[i].time().hour) or ((date_unq[i+1].time().hour == 0) and (date_unq[i].time().hour == 23)):\n",
    "        rest = date_unq[i+1].time().minute + 60 - date_unq[i].time().minute\n",
    "    else:\n",
    "        rest = -1\n",
    "        date_rare.append([date_unq[i+1], date_unq[i]])\n",
    "        #print(\"algo raro\")\n",
    "    date_rest.append(rest)\n",
    "    if rest != 15:\n",
    "        date_no_15.append([rest, date_unq[i+1], date_unq[i]])\n",
    "\n",
    "print(f'\\nTotal DateTimes = {len(date_unq)} vs Total DateTimes in 2 years with a period of 15 min = {(60/15)*24*365*2} --> DateLoss = {100 - (100*(len(date_unq)/((60/15)*24*365*2)))}')\n",
    "print(f'Periods other than 15 min = {len(date_no_15)}\\n')\n",
    "\n",
    "# Datos Raros\n",
    "print(f'Very high periods (2h a 2 días) = {len(date_rare)}')\n",
    "print(date_rare)\n",
    "\n",
    "num = list(np.unique(date_rest))\n",
    "count = np.zeros(len(num))\n",
    "for i in date_no_15:\n",
    "    if i[0] in num:\n",
    "        count[num.index(i[0])] += 1\n",
    "count[num.index(15)] = len(date_unq) - len(date_no_15)\n",
    "\n",
    "fusion = []\n",
    "for i in range(len(num)):\n",
    "    fusion.append([num[i], count[i]])\n",
    "print('\\nPeriods vs number of samples')\n",
    "print(fusion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Revisar cuantos muetreos son diferentes a 15min\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primera instancia lo que se observa es que existen gaps o irregularidades en la frecuencia de muestreo de datos pues se tienen 63092 muestras en un plazo de 2 años, en vez de las 70080 que se deberían tener si se mantuviera un período de muestreo constante de 15min. De hecho más de la mitad de las muestras (38470) poseen un período de muestreo distinto a 15 minutos. De estas 38470 muestras, 24622 tienen un período de muestreo de 16 min, y 6627 lo tienen de 17 min, por lo que podemos decir que el 90% de las muestras se encuentra alrededor de los 15 min, con una desviación de +-2 min. El otro 10% varía muchisimo, llendo desde 1 minuto hasta casi 2 días en los caso más extremos.\n",
    "\n",
    "Hay 21 casos con períodos de muestreo muy altos. La mayoría de estos se dan una vez al mes, siento el patro que más se repite: muestra ~22:30h y luego la siguiente muestra a las ~05:30h del día siguiente. Existe un sólo caso donde no hubo muestras por todo un día y parte del otro ([Timestamp('2018-05-10 07:46:46'), Timestamp('2018-05-08 22:17:57')] --> No hubo muestars el día 2018-05-09)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the first instance we can observe that there are gaps or irregularities in the sampling periods, since there are 63.092 samples in a period of 2 years, instead of the 70.080 that should be had if a constant sampling period of 15 minutes were maintained. In fact, more than half of the samples (38.470) have a sampling period other than 15 minutes. Of these 38.470 samples, 24.622 have a sampling period of 16 min, and 6.627 have a sampling period of 17 min, so we can say that 90% of the samples are around 15 min, with a deviation of +-2 min. The other 10% varies a lot, ranging from 1 minute to almost 2 days in the most extreme cases.\n",
    "\n",
    "There are 21 cases with very high sampling periods. The majority of these occur once a month, with the most repeated pattern being: a sample at ~22:30h and then the next sample at ~05:30h the following day. There is only one case where there were no samples for all day and part of the other ([Timestamp('2018-05-10 07:46:46'), Timestamp('2018-05-08 22:17:57')] --> No samples on 2018-05-09)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agrupamiento de la data\n",
    "Se agrupa la data por DateTime y por DetectID. Esto se hace para que los valores de la variables para un detector sean el mean() de los valores de todas sus \"Lanes\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data grouping\n",
    "The data is grouped by DateTime and DetectID. This is done so that the values of the variables for a detector are the mean() of the values of all its \"Lanes\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.groupby(['DateTimeStamp','DetectID'], as_index=False).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Mean of all Lanes\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Head de los Datos\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data['DetectID'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Descripción de la Data Numérica\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe(include=['datetime64[ns]', 'object'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Descripción de la data no numérica\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.info())\n",
    "print(f'Shape of the data = {data.shape}')\n",
    "#print(data.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Tipo de data y forma del dataframe\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('NA Count:')\n",
    "print(data.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Conteo de NA\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Valid Values: {len(data['Invalid'][data['Invalid'] == 0])} ({(len(data['Invalid'][data['Invalid'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid Values: {len(data['Invalid'][data['Invalid'] != 0])} ({(len(data['Invalid'][data['Invalid'] != 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 1: {len(data['Invalid'][data['Invalid'] == 1])} ({(len(data['Invalid'][data['Invalid'] == 1])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 2: {len(data['Invalid'][data['Invalid'] == 2])} ({(len(data['Invalid'][data['Invalid'] == 2])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 3: {len(data['Invalid'][data['Invalid'] == 3])} ({(len(data['Invalid'][data['Invalid'] == 3])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Invalid Values: {len(data['Invalid'].unique())}\")\n",
    "hist = data['Invalid'].hist(bins=len(data['Invalid'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['Invalid'][data['Invalid'] != 0].hist(bins=len(data['Invalid'].unique()) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data[data['Invalid'] == 0]\n",
    "print(data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Correct Values: {len(data['Failure'][data['Failure'] == 0])} ({(len(data['Failure'][data['Failure'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Failure Values: {len(data['Failure'][data['Failure'] != 0])} ({(len(data['Failure'][data['Failure'] != 0])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Failure Values: {len(data['Failure'].unique())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data[data['Failure'] == 0]\n",
    "print(data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El siguiente es un histograma que representa el número de muestra que se tienen de cada detector. (Recordar que el número total de muestras de DateTime = 63092)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is a histogram representing the number of samples you have from each detector. (Recall that the total number of samples of DateTime = 63092)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['DetectID'].hist(bins=len(data['DetectID'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Histograma de muestras de cada detector\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En la siguientes celdas se ven los números representados en el histograma en forma \"total\" y en forma de porcentaje con respecto al número total de muestras de DateTime."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next cells you see the numbers represented in the histogram in \"total\" form and as a \"percentage\" of the total number of DateTime samples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Samples by detector \"Totals\"')\n",
    "data.groupby('DetectID')['DateTimeStamp'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Conteo de muestras por detector\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Samples by detector \"Percentage\"')\n",
    "detect_count_per = data.groupby('DetectID')['DateTimeStamp'].count()*100/63092\n",
    "print(detect_count_per)\n",
    "\n",
    "theshod = 64\n",
    "print(f'Theshod = {theshod}')\n",
    "valid_detect = detect_count_per[detect_count_per > theshod].index\n",
    "print(f'Valid detectors = {len(valid_detect)}')\n",
    "print(valid_detect)\n",
    "hist = data['DetectID'][data['DetectID'].isin(valid_detect)].hist(bins=len(data['DetectID'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data[data['DetectID'].isin(valid_detect)]\n",
    "print(data.shape)\n",
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data of the I15 SB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Carga de la data.\n",
    "La base de datos SQL posee datos del 01-01-2018 al 31-12-2019 de todos los sensores (a excepción de algunos parecen no estar funcionando) que aparecen en la plataforma Bugatti FAST. De esta base de datos se exportó un dataset con los datos de los sensores pertenecientes a la I15_SB (I15 dirección sur). El dataset \"lean\" es el mismo dataset exportado eliminando las columnas de datos que no utilizo (Vease los drops que se encuentran comentados). Existen dos valores denominados \"Invalid\" -> [0, 1, 2, 3] y \"Failure\" -> [0 - 448] que aún no sé como utilizar porque no sé qué significan sus valores."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data loading\n",
    "The SQL database has data from 01-01-2018 to 31-12-2019 of all the sensors that appear in the Bugatti FAST dashboard (except for some that seem not to be working). From this database a dataset was exported with data from sensors belonging to the I15_NB (I15 northbound). The \"lean\" dataset is the same dataset exported, but eliminating the columns of data that I do not use (see commented \"drops\"). There are two values named \"Invalid\" -> [0, 1, 2, 3] and \"Failure\" -> [0 - 448] that I still don't know how to use because I don't know what their values mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_file_name = \"datasets/la_vegas/i15_bugatti/bugatti_sb_data_lean.csv\"\n",
    "# data_file_name = \"datasets/la_vegas/i15_bugatti/bugatti_sb_data.csv\"\n",
    "\n",
    "data = pd.read_csv(data_file_name)\n",
    "# data = data.drop(columns=['Path', 'RoadIndex', 'RoadwayID', 'SegmentID', 'DeviceID',\n",
    "#                           'Volume1', 'Volume2', 'Volume3', 'Volume4', 'Volume5', 'Volume6',\n",
    "#                           'RoadType', 'Location', 'Polling_Period', 'DayOfWeek',\n",
    "#                           'DateValue', 'HourIdx', 'Holiday'])\n",
    "# data.to_csv('bugatti_sb_data_lean.csv', index=False)\n",
    "\n",
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%   Data Load\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(data['Path'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Invalid Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invalid = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_bad = data[data['Invalid'] == 1]\n",
    "print(data_bad['Invalid'].count())\n",
    "data_bad.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invalid = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_bad = data[data['Invalid'] == 2]\n",
    "print(data_bad['Invalid'].count())\n",
    "data_bad.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invalid = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_bad = data[data['Invalid'] == 3]\n",
    "print(data_bad['Invalid'].count())\n",
    "data_bad.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Valid Values: {len(data['Invalid'][data['Invalid'] == 0])} ({(len(data['Invalid'][data['Invalid'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid Values: {len(data['Invalid'][data['Invalid'] != 0])} ({(len(data['Invalid'][data['Invalid'] != 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 1: {len(data['Invalid'][data['Invalid'] == 1])} ({(len(data['Invalid'][data['Invalid'] == 1])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 2: {len(data['Invalid'][data['Invalid'] == 2])} ({(len(data['Invalid'][data['Invalid'] == 2])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 3: {len(data['Invalid'][data['Invalid'] == 3])} ({(len(data['Invalid'][data['Invalid'] == 3])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Invalid Values: {len(data['Invalid'].unique())}\")\n",
    "hist = data['Invalid'].hist(bins=len(data['Invalid'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zoom on the Invalid values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['Invalid'][data['Invalid'] != 0].hist(bins=len(data['Invalid'].unique()) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data['Invalid'][(data['Invalid'] == 2) & (data['Volume'] == 0) & (data['Occupancy'] == 0)] = 4\n",
    "data_invalid2_special = data.loc[(data['Invalid'] == 2) & (data['Volume'] == 0) & (data['Occupancy'] == 0), 'Invalid']\n",
    "data.loc[(data['Invalid'] == 2) & (data['Volume'] == 0) & (data['Occupancy'] == 0), 'Invalid'] = 0\n",
    "print(f\"Number of Invalid = 2 (Special case): {len(data_invalid2_special)} ({(len(data_invalid2_special)/len(data))*100}%)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['Invalid'][data['Invalid'] != 0].hist(bins=len(data['Invalid'].unique()) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Correct Values: {len(data['Failure'][data['Failure'] == 0])} ({(len(data['Failure'][data['Failure'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Failure Values: {len(data['Failure'][data['Failure'] != 0])} ({(len(data['Failure'][data['Failure'] != 0])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Failure Values: {len(data['Failure'].unique())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Failure Values: {len(data['Failure'][data['Failure'] != 0])}\")\n",
    "print(f\"Number Unique of Failure Values: {len(data['Failure'].unique())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detectors_sb_list = ['395.2.106',\n",
    "  '394.3.104',\n",
    "  '390.1.252',\n",
    "  '390.2.250',\n",
    "  '390.3.249',\n",
    "  '389.1.248',\n",
    "  '389.2.247',\n",
    "  '388.1.245',\n",
    "  '388.2.244',\n",
    "  '388.3.243',\n",
    "  '161.1.242',\n",
    "  '161.2.241',\n",
    "  '155.1.240',\n",
    "  '155.2.239',\n",
    "  '156.2.57',\n",
    "  '147.2.56',\n",
    "  '142.1.55',\n",
    "  '142.2.54',\n",
    "  '132.1.80',\n",
    "  '136.1.47',\n",
    "  '136.2.47',\n",
    "  '123.2.50',\n",
    "  '117.1.46',\n",
    "  '117.2.46',\n",
    "  '117.3.43',\n",
    "  '111.1.42',\n",
    "  '102.1.40',\n",
    "  '102.2.606',\n",
    "  '102.3.37',\n",
    "  '98.2.34',\n",
    "  '98.3.32',\n",
    "  '91.1.31',\n",
    "  '91.2.29',\n",
    "  '92.2.27',\n",
    "  '76.2.26',\n",
    "  '77.2.24',\n",
    "  '78.1.20',\n",
    "  '78.2.20',\n",
    "  '64.1.19',\n",
    "  '69.1.52',\n",
    "  '69.2.16',\n",
    "  '56.1.14',\n",
    "  '57.1.13',\n",
    "  '57.2.11',\n",
    "  '57.3.10',\n",
    "  '40.1.9',\n",
    "  '41.1.95',\n",
    "  '41.2.140',\n",
    "  '17.2.141',\n",
    "  '348.1.149',\n",
    "  '348.2.151',\n",
    "  '348.3.150',\n",
    "  '349.1.154',\n",
    "  '349.3.152',\n",
    "  '350.1.158',\n",
    "  '350.2.159',\n",
    "  '350.3.314',\n",
    "  '351.1.315',\n",
    "  '351.2.316',\n",
    "  '351.3.317',\n",
    "  '352.1.318',\n",
    "  '352.2.321',\n",
    "  '352.3.322',\n",
    "  '353.1.323',\n",
    "  '353.2.324',\n",
    "  '422.1.326',\n",
    "  '422.2.328',\n",
    "  '423.1.329',\n",
    "  '423.2.330',\n",
    "  '423.3.331',\n",
    "  '424.1.332',\n",
    "  '424.2.333',\n",
    "  '424.3.334',\n",
    "  '425.1.335']\n",
    "print(len(detectors_sb_list))\n",
    "detector_id_map = {}\n",
    "data_unique_detect_ID = data['DetectorID'].unique()\n",
    "\n",
    "count_loss = 0\n",
    "for i in range(len(detectors_sb_list)):\n",
    "    if detectors_sb_list[i] in data_unique_detect_ID:\n",
    "        detector_id_map[detectors_sb_list[i]] = i - count_loss\n",
    "    else:\n",
    "        count_loss += 1\n",
    "print(f'Detectors lost = {count_loss}')\n",
    "\n",
    "data_detect_ID = data['DetectorID']\n",
    "\n",
    "data_detect_new_ID = pd.Series([detector_id_map[i] for i in data_detect_ID])\n",
    "print(data_detect_new_ID)\n",
    "data['DetectID'] = data_detect_new_ID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['DateTimeStamp'] = pd.to_datetime(data['DateTimeStamp'])\n",
    "data = data.sort_values(by=['DateTimeStamp','DetectID'],ascending=[True, True])\n",
    "\n",
    "date_time_obj = data['DateTimeStamp'].iloc[0]\n",
    "print('Date:', date_time_obj.date())\n",
    "print('Time:', date_time_obj.time())\n",
    "print('Minute:', date_time_obj.time().minute)\n",
    "print('Date-time:', date_time_obj)\n",
    "\n",
    "print(data['DateTimeStamp'].unique())\n",
    "print(len(data['DateTimeStamp'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Convertir columna 'DateTimeStamp' a pd.dateTime64 object y sortearlo ascendentemente\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_unq = pd.Series(data['DateTimeStamp'].unique())\n",
    "date_rest = []\n",
    "date_rare = []\n",
    "date_no_15 = []\n",
    "for i in range(len(date_unq)-1):\n",
    "    if date_unq[i+1].time().hour == date_unq[i].time().hour:\n",
    "        rest = date_unq[i+1].time().minute - date_unq[i].time().minute\n",
    "    elif (date_unq[i+1].time().hour > date_unq[i].time().hour) or ((date_unq[i+1].time().hour == 0) and (date_unq[i].time().hour == 23)):\n",
    "        rest = date_unq[i+1].time().minute + 60 - date_unq[i].time().minute\n",
    "    else:\n",
    "        rest = -1\n",
    "        date_rare.append([date_unq[i+1], date_unq[i]])\n",
    "        #print(\"algo raro\")\n",
    "    date_rest.append(rest)\n",
    "    if rest != 15:\n",
    "        date_no_15.append([rest, date_unq[i+1], date_unq[i]])\n",
    "\n",
    "print(f'\\nTotal DateTimes = {len(date_unq)} vs Total DateTimes in 2 years with a period of 15 min = {(60/15)*24*365*2} --> DateLoss = {100 - (100*(len(date_unq)/((60/15)*24*365*2)))}')\n",
    "print(f'Periods other than 15 min = {len(date_no_15)}\\n')\n",
    "\n",
    "# Datos Raros\n",
    "print(f'Very high periods (2h a 2 días) = {len(date_rare)}')\n",
    "print(date_rare)\n",
    "\n",
    "num = list(np.unique(date_rest))\n",
    "count = np.zeros(len(num))\n",
    "for i in date_no_15:\n",
    "    if i[0] in num:\n",
    "        count[num.index(i[0])] += 1\n",
    "count[num.index(15)] = len(date_unq) - len(date_no_15)\n",
    "\n",
    "fusion = []\n",
    "for i in range(len(num)):\n",
    "    fusion.append([num[i], count[i]])\n",
    "print('\\nPeriods vs number of samples')\n",
    "print(fusion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Revisar cuantos muetreos son diferentes a 15min\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.groupby(['DateTimeStamp','DetectID'], as_index=False).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Mean of all Lanes\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Head de los Datos\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Descripción de la Data Numérica\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe(include=['datetime64[ns]', 'object'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Descripción de la data no numérica\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.info())\n",
    "print(f'Shape of the data = {data.shape}')\n",
    "#print(data.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Tipo de data y forma del dataframe\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('NA Count:')\n",
    "print(data.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Conteo de NA\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Valid Values: {len(data['Invalid'][data['Invalid'] == 0])} ({(len(data['Invalid'][data['Invalid'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid Values: {len(data['Invalid'][data['Invalid'] != 0])} ({(len(data['Invalid'][data['Invalid'] != 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 1: {len(data['Invalid'][data['Invalid'] == 1])} ({(len(data['Invalid'][data['Invalid'] == 1])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 2: {len(data['Invalid'][data['Invalid'] == 2])} ({(len(data['Invalid'][data['Invalid'] == 2])/len(data))*100}%)\")\n",
    "print(f\"Number of Invalid = 3: {len(data['Invalid'][data['Invalid'] == 3])} ({(len(data['Invalid'][data['Invalid'] == 3])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Invalid Values: {len(data['Invalid'].unique())}\")\n",
    "hist = data['Invalid'].hist(bins=len(data['Invalid'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['Invalid'][data['Invalid'] != 0].hist(bins=len(data['Invalid'].unique()) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of Correct Values: {len(data['Failure'][data['Failure'] == 0])} ({(len(data['Failure'][data['Failure'] == 0])/len(data))*100}%)\")\n",
    "print(f\"Number of Failure Values: {len(data['Failure'][data['Failure'] != 0])} ({(len(data['Failure'][data['Failure'] != 0])/len(data))*100}%)\")\n",
    "\n",
    "print(f\"Number Unique of Failure Values: {len(data['Failure'].unique())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = data['DetectID'].hist(bins=len(data['DetectID'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Histograma de muestras de cada detector\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Samples by detector \"Totals\"')\n",
    "data.groupby('DetectID')['DateTimeStamp'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  Conteo de muestras por detector\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Samples by detector \"Percentage\"')\n",
    "data.groupby('DetectID')['DateTimeStamp'].count()*100/63092\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}